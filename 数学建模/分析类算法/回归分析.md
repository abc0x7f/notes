# 回归分析
## 参考资料
[9.1 回归分析的基本理论和一般线性回归分析_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1jX4y1P7V5/?buvid=Z841938EE8D112B242ADAC77DE19C71AA52C&is_story_h5=false&mid=E2W9mGyWL5bSYxfnaxwhcQ%3D%3D&p=46&plat_id=114&share_from=ugc&share_medium=iphone&share_plat=ios&share_source=QQ&share_tag=s_i&timestamp=1742444494&unique_k=CZoypmb&up_id=630304558&vd_source=240e7300a6abd1dfda891d2d7ad9bdc1)
[9.2 带虚拟解释变量的回归分析_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1jX4y1P7V5?buvid=Z841938EE8D112B242ADAC77DE19C71AA52C&is_story_h5=false&mid=E2W9mGyWL5bSYxfnaxwhcQ%3D%3D&plat_id=114&share_from=ugc&share_medium=iphone&share_plat=ios&share_source=QQ&share_tag=s_i&timestamp=1742444494&unique_k=CZoypmb&up_id=630304558&vd_source=240e7300a6abd1dfda891d2d7ad9bdc1&p=47&spm_id_from=333.788.videopod.episodes)
## 定义
通过回归方程的形式描述和反映事物之间的数量关系.
1. 局部平均: 回归线的近似线,需要较大样本.
2. 拟合函数: 估计回归模型的各个参数来得到模型.
## 步骤
1. 确定解释变量(自变量),被解释变量(因变量).
2. 确定回归模型: 根据函数拟合方式和散点图.
3. 建立回归模型: 根据样本数据,估计模型中的参数.
4. 对回归方程进行各种统计检验.
5. 利用回归模型进行预测.
## 线性回归模型
一元线性模型: $y=\beta_0+\beta_1x+\epsilon$
多元线性回归模型:
$$y=\beta_0+\beta_1x_1+\beta_2x_2+...+\beta_px_p+\epsilon$$
## 统计检验
### 拟合优度检验
一元线性回归方程的拟合优度检验为$R^2$**统计量**,称为判定系数或决定系数.$R^2\in[0,1]$,且越接近$1$拟合优度越高.
多元线性回归方程的拟合优度检验为$\overline{R^2}$统计量,称为调整的判定系数或调整的决定系数.
### 回归方程的显著性检验(线性关系检验)
$F$检验.
一元线性回归方程的原假设$H_0$是回归系数$\beta_0=0$,即与$0$无显著差异.
多元线性回归方程的原假设$H_0$是偏回归系数$\beta_0=\beta_1=...=\beta_p=0$,即与$0$无显著差异.备择假设是偏回归系数中至少有一个不等于$0$.
注意:多元线性回归方程中,即使通过了**回归方程的显著性检验**,也不能保证回归方程中不存在不能较好地解释$y$的$x_i$.
### 两者关系
有一定的正向相关关系.但显著性检验是统计学上的假设检验问题,而拟合优度不是.拟合优度可看作一个统计量,不涉及总体线性关系的推断.
### 回归系数的显著性检验
$t$检验.
检验每个解释变量是否能有效地解释被解释变量的线性变化.
一元线性回归方程:原假设$H_0$为$\beta_1=0$.
多元线性回归方程:原假设$H_0$为$\beta_i=0$.
### 残差分析
>残差是预测值与实际样本值之间的差距.

1. 残差均值为0的正态性分析.
2. 残差的独立性检验.
>绘制残差序列图
>计算残差的自相关系数
>DW检验
3. 异方差检验: 残差的方差应该相等.
>绘制残差图
>等级相关分析
4. 探测样本中的异常值.
## 多元回归分析中的其他问题
### 解释变量的筛选问题
解释变量较少则不能很好地说明被解释变量的变化.但并非引入的变量越多越好,原因:
>有些自变量对因变量的解释没有贡献.
>自变量自建可能存在较强的线性关系,即**多重共线性**,不能同时引入方程.
1. 向前筛选策略: 自变量不断进入方程的过程.
>首先选择与因变量具有最高相关系数的自变量进入方程,并进行各种检验.
>其次再剩余自变量中寻找**偏相关系数最高**的变量进入回归方程(默认回归系数检验的概率值小于$PIN(0.05)$才可以进入方程).
>反复进行上述步骤.
2. 向后筛选策略: 自变量不断剔除出方程的过程.
>首先将所有自变量引入方程.
>其次将$t$值最小的自变量剔除出去(默认回归系数检验值大于$POUT(0.10)$则剔出方程).
>若新方程中所有变量的回归系数$t$值都是显著的则筛选过程结束.
3. 逐步筛选策略: 结合.
>在每个阶段都考虑剔除一个变量额的可能性(减小变量之间相关性的影响).
### 变量的多重共线性问题
主要问题: 回归系数的标准差随自变量相关性的增大而增大,以至使回归系数的置信区间不断增大,造成估计值精度减低.
共线性诊断:
1. 自变量的容忍度和方差膨胀因子.
容忍度$Tol_i=1-R^2$,$R_i$表示自变量$x_i$与其他自变量间负相关系数的平方,方差膨胀因子(VIF)为容忍度的倒数.
$Tol_i\in [0,1]$越接近$0$,VIF越接近$+\infty$,表示多重共线性越强,越不应该进入方程.若$VIF\geq10$说明解释变量之间有严重的多重共线性,可能会影响到最小二乘估计.
2. 用特征根刻画自变量的方差.
从自变量的相关系数矩阵出发,得到相应的若干成分.若某个特征根能同时刻画多个自变量方差的较大比例(0.7),则表明这些自变量之间存在较强的多重共线性.
3. 条件指标(条件指数).
$0<k<10$无多重共线性;$10\leq k\leq 30$较强;$k\geq 30$严重.
# 带虚拟解释变量的回归分析
当解释变量是**分类型变量**时,不能直接进行回归分析.
通常将分类解释变量转换成若干个值为1或0的变量,这种变量称为**虚拟变量**或哑变量.
多个虚拟变量之间具有完全线性关系(总和为1),如果都参与回归分析,会导致完全共线性问题.所以如果类型解释变量有$k$个类别值,只需引入前$k-1$个虚拟变量.
>季节变量(春夏秋冬):春季(1-0),夏季(1-0),秋季(1-0).

